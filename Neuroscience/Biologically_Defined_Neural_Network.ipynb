{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Biologically-Defined Neural Network",
      "provenance": [],
      "authorship_tag": "ABX9TyPrLoMWApNyW/16MX1llbZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/convolutionalNN/Projects-For-Fun/blob/master/Neuroscience/Biologically_Defined_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9DBZFZVcW0k",
        "colab_type": "text"
      },
      "source": [
        "**Credit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toLVeqQsOZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################################\n",
        "#    ORIGINAL SOURCE CODE:\n",
        "#    Title: <Simple Neural Network with 1 hidden layer with the number\n",
        "#    of hidden units as a hyperparameter to calculate the XOR function>\n",
        "#    Author: <Kitsios Konstantinos>\n",
        "#    Date: <Nov 10, 2018>\n",
        "#    Code version: <1.0.1>\n",
        "#    Availability: <https://github.com/kitsiosk/xor-neural-net/blob/master/neural_net.py>\n",
        "#\n",
        "#######################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqNpdmimcb5x",
        "colab_type": "text"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epx9ehXNeoYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQCcH8ylcfBo",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv0FGcDeeVqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_h = 8\n",
        "n_x = 8\n",
        "n_y = 1\n",
        "r_h = 0.35\n",
        "\n",
        "threshold_activation = 5 #threshold for activation potential\n",
        "homeostatic_threshold = 0.999\n",
        "num_of_iters = 1000\n",
        "learning_rate = 0.3\n",
        "potentiation = .0125\n",
        "depression = -.0045\n",
        "delta = 0.05\n",
        "\n",
        "binary1 = 0\n",
        "binary2 = 1\n",
        "sequence1 = 4\n",
        "sequence2 = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNWp257UcmaN",
        "colab_type": "text"
      },
      "source": [
        "**Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERBgEXHeNeXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates array of 8-bit binary sequences (0-191); shape of array is 8x191\n",
        "X_train = []\n",
        "for i in range(0,191):\n",
        "  X_train.append([i])\n",
        "X_train = np.array(X_train, dtype=np.uint8)\n",
        "X_train = np.unpackbits(X_train, axis=1)\n",
        "X_train = np.rot90(X_train, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmPD_U-3Q5Vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates array of 8-bit binary sequences (192-256) shape of array is 8x64\n",
        "X_test = []\n",
        "for i in range(192,256):\n",
        "  X_test.append([i])\n",
        "X_test = np.array(X_test, dtype=np.uint8)\n",
        "X_test = np.unpackbits(X_test, axis=1)\n",
        "X_test = np.rot90(X_test, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83TrSpmFR2XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label each training binary sequence with 1 or 0 based on arbitrary rule (i.e. 1 if 5th digit is a 0 and 7th digit is a 1; else 0)\n",
        "Y_train = []\n",
        "for i in range(0,191):\n",
        "  if(X_train[sequence1][i] == binary1 and X_train[sequence2][i] == binary2):\n",
        "    Y_train.append(1)\n",
        "  else:\n",
        "    Y_train.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDK9PSD-R6Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#same for test\n",
        "Y_test = []\n",
        "for i in range(0, 63):\n",
        "  if(X_test[sequence1][i] == binary1 and X_test[sequence2][i] == binary2):\n",
        "    Y_test.append(1)\n",
        "  else:\n",
        "    Y_test.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InR0Q-RiMuzt",
        "colab_type": "code",
        "outputId": "1da3d43d-bd89-40d3-f642-867d5dfc9ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#initialize for LTPD function\n",
        "R0_factor = []\n",
        "R1_factor = []\n",
        "R2_factor = []\n",
        "R3_factor = []\n",
        "R1_previous = []\n",
        "R2_previous = []\n",
        "R3_previous = []\n",
        "\n",
        "X = X_train #8x191\n",
        "Y = np.array(Y_train) #1x191\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "def initialize_parameters(n_x, n_h, n_y, r_h):\n",
        "    global R0, R1, R2, R3\n",
        "    \n",
        "    W1 = np.random.randn(n_h, n_x) #8x8\n",
        "    b1 = np.zeros((n_h, n_y)) #8x1\n",
        "    W2 = np.random.randn(n_h, n_x) #8x8\n",
        "    b2 = np.zeros((n_h, n_y)) #8x1\n",
        "    W3 = np.random.randn(n_h, n_x) #8x8\n",
        "    b3 = np.zeros((n_h, n_y)) #8x1\n",
        "    W4 = np.random.randn(n_y, n_x) #1x8\n",
        "    b4 = np.zeros((n_y, n_y)) #1x1\n",
        "    R0 = np.full((n_h, np.shape(X)[1]), r_h) #8x191\n",
        "    R1 = np.full((n_h, np.shape(X)[1]), r_h) #8x191\n",
        "    R2 = np.full((n_h, np.shape(X)[1]), r_h) #8x191\n",
        "    R3 = np.full((n_h, np.shape(X)[1]), r_h) #8x191\n",
        "\n",
        "    #initialize parameters\n",
        "    parameters = {\n",
        "        \"W1\": W1,\n",
        "        \"b1\": b1,\n",
        "        \"W2\": W2,\n",
        "        \"b2\": b2,\n",
        "        \"W3\": W3,\n",
        "        \"b3\": b3,\n",
        "        \"W4\": W4,\n",
        "        \"b4\": b4,\n",
        "    }\n",
        "    return parameters\n",
        "\n",
        "#depending on the length of the columns of W (n), each element in A will become an array of 1xn\n",
        "#this would turn a 8x191 array corresponding with 8x8 array into a 8x191x8 array\n",
        "def split(A,W):\n",
        "  A_new = []\n",
        "  for x in range(np.shape(A)[0]):\n",
        "    store = []\n",
        "    for y in range(np.shape(A)[1]): \n",
        "      keep = []\n",
        "      for i in range(np.shape(W)[0]):\n",
        "        keep.append(A[x][y])\n",
        "      store.append(keep)\n",
        "    A_new.append(store)\n",
        "  A = A_new\n",
        "  return A\n",
        "\n",
        "#essentially the dot product for a 3 dimensional array; yields the same shape as a dot product would\n",
        "def R_dot(A, W):  \n",
        "  new_Z = []\n",
        "  for y in range(np.shape(A)[1]):\n",
        "    Z_sum = []\n",
        "    for x in range(np.shape(A)[0]):  \n",
        "      Z = np.multiply(A[x][y], np.transpose(W)[x]) #hadamard product\n",
        "      Z_sum.append(Z)\n",
        "    new_Z.append(np.sum(Z_sum, axis=0)) #sum all numbers in each column\n",
        "  Z = new_Z\n",
        "  Z = np.squeeze(Z).tolist()\n",
        "  Z = np.transpose(Z)\n",
        "  return Z\n",
        "\n",
        "def forward_prop(X, parameters):\n",
        "\n",
        "    global R0_factor, R1_factor, R2_factor, R3_factor, R1_previous, R2_previous, R3_previous, R0, R1, R2, R3, OX, OA1, OA2, OA3, A3\n",
        "    \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    b3 = parameters[\"b3\"]\n",
        "    W4 = parameters[\"W4\"]\n",
        "    b4 = parameters[\"b4\"]\n",
        "\n",
        "    OX = X\n",
        "    X = split(X, W1)\n",
        "    if(i == 0):\n",
        "      R0 = split(R0, W1)\n",
        "    neurotransmitter(X, R0)\n",
        "    R0_factor = []\n",
        "    LTPD(X, R0, R0_factor)\n",
        "    R0 = homeostatic(R0)\n",
        "    Z1 = R_dot(X, W1) + b1\n",
        "    activation(Z1)\n",
        "    A1 = np.tanh(Z1)\n",
        "    \n",
        "    OA1 = A1\n",
        "    A1 = split(A1, W2)\n",
        "    if(i == 0):\n",
        "      R1 = split(R1, W2)\n",
        "    neurotransmitter(A1, R1)\n",
        "    R1_factor = []\n",
        "    LTPD(A1, R1, R1_factor)\n",
        "    R1 = homeostatic(R1)\n",
        "    Z2 = R_dot(A1, W2) + b2\n",
        "    activation(Z2)\n",
        "    A2 = np.tanh(Z2)\n",
        "\n",
        "\n",
        "\n",
        "    OA2 = A2\n",
        "    A2 = split(A2, W2)\n",
        "    if(i == 0):\n",
        "      R2 = split(R2, W2)\n",
        "    neurotransmitter(A2, R2)\n",
        "    R2_factor = []\n",
        "    LTPD(A2, R2, R2_factor)\n",
        "    R2 = homeostatic(R2)\n",
        "    Z3 = R_dot(A2, W3) + b3\n",
        "    activation(Z3)\n",
        "    A3 = np.tanh(Z3)\n",
        "\n",
        "    OA3 = A3\n",
        "    A3 = split(A3, W4)\n",
        "    if(i == 0):\n",
        "      R3 = split(R3, W4)\n",
        "    \n",
        "    R3 = neurotransmitter(A3, R3)\n",
        "    R3_factor = []\n",
        "    LTPD(A3, R3, R3_factor)\n",
        "    R3 = homeostatic(R3)\n",
        "\n",
        "    A3 = np.array(A3)[:, :, 0]\n",
        "    Z4 = np.dot(W4, A3) + b4\n",
        "    A4 = sigmoid(Z4)\n",
        "\n",
        "    cache = {\n",
        "        \"A1\": A1,\n",
        "        \"A2\": A2,\n",
        "        \"A3\": A3,\n",
        "        \"A4\": A4\n",
        "    }\n",
        "    return A4, cache\n",
        "\n",
        "def neurotransmitter(A, R):  \n",
        "  if(np.shape(A)[2]>1):\n",
        "    A = np.transpose(A)\n",
        "    for x in range(np.shape(A)[0]):\n",
        "      for y in range(np.shape(A)[1]):\n",
        "        for z in range(np.shape(A)[2]):\n",
        "          if(A[x][y][z] > R[x][y][z]):\n",
        "            A[x][y][z] = R[x][y][z]\n",
        "          elif(A[x][y][z] < -R[x][y][z]):\n",
        "            A[x][y][z] = -R[x][y][z]\n",
        "    A = np.transpose(A)\n",
        "    return R\n",
        "  else:\n",
        "    A = np.array(A)\n",
        "    R = np.array(R)\n",
        "    A[:, :, 0]\n",
        "    R[:, :, 0]\n",
        "    A = np.transpose(A)\n",
        "    for x in range(np.shape(A)[0]):\n",
        "      for y in range(np.shape(A)[1]):\n",
        "        if(A[x][y].any() > R[x][y].any()): #\n",
        "          A[x][y] = R[x][y]\n",
        "        elif(A[x][y].any() < -1 * R[x][y].any()):\n",
        "          A[x][y] = -1 * R[x][y]\n",
        "    A = np.transpose(A)\n",
        "    return R\n",
        "\n",
        "#if Z < threshold, it should = 0\n",
        "def activation(Z):\n",
        "  for x in range(np.shape(Z)[0]):\n",
        "    for y in range(np.shape(Z)[1]): \n",
        "      if(np.abs(Z[x][y]) < threshold_activation):\n",
        "        Z[x][y] = 0\n",
        "\n",
        "#when element in A==0, corresponding R element subtract small amount (depression)\n",
        "#when element in A!=0, corresponding R element add small amount (potentiation)\n",
        "def LTPD(A, R, R_factor):\n",
        "  for x in range(np.shape(A)[0]):\n",
        "    factor2 = []\n",
        "    for y in range(np.shape(A)[1]):  \n",
        "      factor1 = []\n",
        "      for z in range(np.shape(A)[2]):  \n",
        "        if(A[x][y][z] == 0):\n",
        "          factor1.append(depression)\n",
        "        else:\n",
        "          factor1.append(potentiation)\n",
        "      factor2.append(factor1)   \n",
        "    R_factor.append(factor2)\n",
        "  R = np.transpose(R_factor) + R\n",
        "  for x in range(np.shape(R)[0]):\n",
        "    for y in range(np.shape(R)[1]):  \n",
        "      for z in range(np.shape(R)[2]):\n",
        "        if(R[x][y][z] < 0):\n",
        "          R[x][y][z] = 0\n",
        "  return R\n",
        "\n",
        "def homeostatic(R):\n",
        "  for x in range(np.shape(R)[0]):\n",
        "    for y in range(np.shape(R)[1]):\n",
        "      if(np.amax(R[x][y]) > homeostatic_threshold and np.amax(R[x][y]) > np.abs(np.amin(R[x][y]))):\n",
        "        R[x][y] = R[x][y] - delta * (R[x][y] / (np.amax(R[x][y]) / homeostatic_threshold))\n",
        "      elif(np.amin(R[x][y]) < -homeostatic_threshold and np.abs(np.amin(R[x][y])) > np.amax(R[x][y])):\n",
        "        R[x][y] = R[x][y] - delta * (R[x][y] / (np.amin(R[x][y]) / homeostatic_threshold))\n",
        "  return R\n",
        "\n",
        "\n",
        "def calculate_cost(A4, Y):\n",
        "    cost = -np.sum(np.multiply(Y, np.log(A4)) +  np.multiply(1-Y, np.log(1-A4)))/m\n",
        "    cost = np.squeeze(cost)\n",
        "    return cost\n",
        "\n",
        "def backward_prop(X, Y, cache, parameters):\n",
        "    A1 = cache[\"A1\"]\n",
        "    A2 = cache[\"A2\"]\n",
        "    A3 = cache[\"A3\"]\n",
        "    A4 = cache[\"A4\"]\n",
        "\n",
        "    W4 = parameters[\"W4\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "\n",
        "    dZ4 = A4 - Y\n",
        "    dW4 = np.dot(dZ4, np.array(OA3).T)/m\n",
        "    db4 = np.sum(dZ4, axis=1, keepdims=True)/m\n",
        "    dZ3 = np.multiply(np.dot(W4.T, dZ4), 1-np.power(OA3, 2))\n",
        "    dW3 = np.dot(dZ3, OA2.T)/m\n",
        "    db3 = np.sum(dZ3, axis=1, keepdims=True)/m\n",
        "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1-np.power(OA2, 2))\n",
        "    dW2 = np.dot(dZ2, OA1.T)/m\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m\n",
        "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1-np.power(OA1, 2))\n",
        "    dW1 = np.dot(dZ1, OX.T)/m\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
        "\n",
        "    grads = {\n",
        "        \"dW1\": dW1,\n",
        "        \"db1\": db1,\n",
        "        \"dW2\": dW2,\n",
        "        \"db2\": db2,\n",
        "        \"dW3\": dW3,\n",
        "        \"db3\": db3,\n",
        "        \"dW4\": dW4,\n",
        "        \"db4\": db4\n",
        "    }\n",
        "\n",
        "    return grads\n",
        "\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    b3 = parameters[\"b3\"]\n",
        "    W4 = parameters[\"W4\"]\n",
        "    b4 = parameters[\"b4\"]\n",
        "\n",
        "    dW1 = grads[\"dW1\"]\n",
        "    db1 = grads[\"db1\"]\n",
        "    dW2 = grads[\"dW2\"]\n",
        "    db2 = grads[\"db2\"]\n",
        "    dW3 = grads[\"dW3\"]\n",
        "    db3 = grads[\"db3\"]\n",
        "    dW4 = grads[\"dW4\"]\n",
        "    db4 = grads[\"db4\"]\n",
        "\n",
        "    W1 = W1 - learning_rate*dW1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    W2 = W2 - learning_rate*dW2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    W3 = W3 - learning_rate*dW3\n",
        "    b3 = b3 - learning_rate*db3\n",
        "    W4 = W4 - learning_rate*dW4\n",
        "    b4 = b4 - learning_rate*db4\n",
        "    \n",
        "    new_parameters = {\n",
        "        \"W1\": W1,\n",
        "        \"W2\": W2,\n",
        "        \"b1\" : b1,\n",
        "        \"b2\" : b2,\n",
        "        \"W3\": W3,\n",
        "        \"W4\": W4,\n",
        "        \"b3\" : b3,\n",
        "        \"b4\" : b4\n",
        "    }\n",
        "\n",
        "    return new_parameters\n",
        "\n",
        "\n",
        "def model(X, Y, n_x, n_h, n_y, r_h, num_of_iters, learning_rate):\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y, r_h)\n",
        "\n",
        "    costs = [] #ADDED\n",
        "\n",
        "    global i\n",
        "\n",
        "    for i in range(0, num_of_iters+1):\n",
        "        a4, cache = forward_prop(X, parameters)\n",
        "\n",
        "        cost = calculate_cost(a4, Y)\n",
        "\n",
        "        grads = backward_prop(X, Y, cache, parameters)\n",
        "\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        costs.append(cost) #ADDED\n",
        "\n",
        "        if(i%10 == 0):\n",
        "           costs.append(cost)\n",
        "           print('Cost after iteration# {:d}: {:f}'.format(i, cost))\n",
        "\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('Cost Value of ' + x)\n",
        "    plt.xlabel('Number of Iterations')\n",
        "    plt.axis([0, 1000, 0, 1])\n",
        "\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def predict(X, parameters):\n",
        "    a4, cache = forward_prop(X, parameters)\n",
        "    yhat = a4\n",
        "    yhat = np.squeeze(yhat)\n",
        "    y_predict = yhat\n",
        "    return y_predict\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# No. of training examples\n",
        "m = X.shape[1]\n",
        "\n",
        "x = str(binary1) + ' in the ' + str(sequence1) + ' place and ' + str(binary2) + ' in the ' + str(sequence2) + ' place'\n",
        "\n",
        "#train model\n",
        "trained_parameters = model(X, Y, n_x, n_h, n_y, r_h, num_of_iters, learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration# 0: 0.693147\n",
            "Cost after iteration# 10: 0.491728\n",
            "Cost after iteration# 20: 0.287929\n",
            "Cost after iteration# 30: 0.157815\n",
            "Cost after iteration# 40: 0.041871\n",
            "Cost after iteration# 50: 0.025886\n",
            "Cost after iteration# 60: 0.022493\n",
            "Cost after iteration# 70: 0.009463\n",
            "Cost after iteration# 80: 0.008281\n",
            "Cost after iteration# 90: 0.005966\n",
            "Cost after iteration# 100: 0.006242\n",
            "Cost after iteration# 110: 0.002998\n",
            "Cost after iteration# 120: 0.002959\n",
            "Cost after iteration# 130: 0.002847\n",
            "Cost after iteration# 140: 0.002459\n",
            "Cost after iteration# 150: 0.002106\n",
            "Cost after iteration# 160: 0.002024\n",
            "Cost after iteration# 170: 0.001982\n",
            "Cost after iteration# 180: 0.001666\n",
            "Cost after iteration# 190: 0.001637\n",
            "Cost after iteration# 200: 0.001611\n",
            "Cost after iteration# 210: 0.001585\n",
            "Cost after iteration# 220: 0.001560\n",
            "Cost after iteration# 230: 0.001521\n",
            "Cost after iteration# 240: 0.001498\n",
            "Cost after iteration# 250: 0.001476\n",
            "Cost after iteration# 260: 0.001455\n",
            "Cost after iteration# 270: 0.001434\n",
            "Cost after iteration# 280: 0.001699\n",
            "Cost after iteration# 290: 0.001394\n",
            "Cost after iteration# 300: 0.001430\n",
            "Cost after iteration# 310: 0.001936\n",
            "Cost after iteration# 320: 0.001413\n",
            "Cost after iteration# 330: 0.001394\n",
            "Cost after iteration# 340: 0.001373\n",
            "Cost after iteration# 350: 0.001355\n",
            "Cost after iteration# 360: 0.001037\n",
            "Cost after iteration# 370: 0.000990\n",
            "Cost after iteration# 380: 0.000977\n",
            "Cost after iteration# 390: 0.000914\n",
            "Cost after iteration# 400: 0.000903\n",
            "Cost after iteration# 410: 0.000891\n",
            "Cost after iteration# 420: 0.000880\n",
            "Cost after iteration# 430: 0.000821\n",
            "Cost after iteration# 440: 0.000782\n",
            "Cost after iteration# 450: 0.000773\n",
            "Cost after iteration# 460: 0.000765\n",
            "Cost after iteration# 470: 0.000756\n",
            "Cost after iteration# 480: 0.000748\n",
            "Cost after iteration# 490: 0.000740\n",
            "Cost after iteration# 500: 0.000732\n",
            "Cost after iteration# 510: 0.000725\n",
            "Cost after iteration# 520: 0.000717\n",
            "Cost after iteration# 530: 0.000682\n",
            "Cost after iteration# 540: 0.000648\n",
            "Cost after iteration# 550: 0.000642\n",
            "Cost after iteration# 560: 0.000609\n",
            "Cost after iteration# 570: 0.000583\n",
            "Cost after iteration# 580: 0.000578\n",
            "Cost after iteration# 590: 0.000573\n",
            "Cost after iteration# 600: 0.000568\n",
            "Cost after iteration# 610: 0.000563\n",
            "Cost after iteration# 620: 0.000559\n",
            "Cost after iteration# 630: 0.000554\n",
            "Cost after iteration# 640: 0.000549\n",
            "Cost after iteration# 650: 0.000519\n",
            "Cost after iteration# 660: 0.000515\n",
            "Cost after iteration# 670: 0.000486\n",
            "Cost after iteration# 680: 0.000482\n",
            "Cost after iteration# 690: 0.000478\n",
            "Cost after iteration# 700: 0.000475\n",
            "Cost after iteration# 710: 0.000446\n",
            "Cost after iteration# 720: 0.000443\n",
            "Cost after iteration# 730: 0.000440\n",
            "Cost after iteration# 740: 0.000437\n",
            "Cost after iteration# 750: 0.000433\n",
            "Cost after iteration# 760: 0.000430\n",
            "Cost after iteration# 770: 0.000427\n",
            "Cost after iteration# 780: 0.000424\n",
            "Cost after iteration# 790: 0.000421\n",
            "Cost after iteration# 800: 0.000418\n",
            "Cost after iteration# 810: 0.000416\n",
            "Cost after iteration# 820: 0.000413\n",
            "Cost after iteration# 830: 0.000410\n",
            "Cost after iteration# 840: 0.000407\n",
            "Cost after iteration# 850: 0.000404\n",
            "Cost after iteration# 860: 0.000402\n",
            "Cost after iteration# 870: 0.000399\n",
            "Cost after iteration# 880: 0.000396\n",
            "Cost after iteration# 890: 0.000394\n",
            "Cost after iteration# 900: 0.000391\n",
            "Cost after iteration# 910: 0.000389\n",
            "Cost after iteration# 920: 0.000386\n",
            "Cost after iteration# 930: 0.000384\n",
            "Cost after iteration# 940: 0.000381\n",
            "Cost after iteration# 950: 0.000379\n",
            "Cost after iteration# 960: 0.000377\n",
            "Cost after iteration# 970: 0.000374\n",
            "Cost after iteration# 980: 0.000372\n",
            "Cost after iteration# 990: 0.000370\n",
            "Cost after iteration# 1000: 0.000368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}